# -*- coding: utf-8 -*-
"""task5_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1X2DzOOtpq02LXNedSySgUBZUy95SnFjQ
"""

!pip install -q torch transformers gradio accelerate huggingface_hub

import gradio as gr
from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline

model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"

tokenizer = AutoTokenizer.from_pretrained(model_name)
model = AutoModelForCausalLM.from_pretrained(
    model_name,
    device_map="auto",
    torch_dtype="auto"
)

generator = pipeline(
    "text-generation",
    model=model,
    tokenizer=tokenizer
)

def generate_text(prompt):
    result = generator(
        prompt,
        max_length=150,
        temperature=0.7
    )
    return result[0]["generated_text"]

demo = gr.Interface(
    fn=generate_text,
    inputs=gr.Textbox(lines=3, placeholder="Enter your prompt"),
    outputs="text",
    title="DeepSeek Text Generator",
    allow_flagging="never",
    description="Text generation using DeepSeek model"
)

demo.launch(share=True)

# Commented out IPython magic to ensure Python compatibility.
# %%writefile app.py
# import gradio as gr
# from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline
# 
# model_name = "deepseek-ai/DeepSeek-R1-Distill-Qwen-1.5B"
# 
# tokenizer = AutoTokenizer.from_pretrained(model_name)
# model = AutoModelForCausalLM.from_pretrained(
#     model_name,
#     device_map="auto",
#     torch_dtype="auto"
# )
# 
# generator = pipeline("text-generation", model=model, tokenizer=tokenizer)
# 
# def generate_text(prompt):
#     output = generator(prompt, max_length=150, temperature=0.7)
#     return output[0]["generated_text"]
# 
# gr.Interface(
#     fn=generate_text,
#     inputs=gr.Textbox(lines=3, placeholder="Enter a prompt"),
#     outputs="text",
#     title="DeepSeek Text Generation App"
# ).launch()

# Commented out IPython magic to ensure Python compatibility.
# %%writefile requirements.txt
# torch
# transformers
# gradio
# accelerate

from huggingface_hub import login
login()

!git clone https://huggingface.co/spaces/Nandita12/text-generation

cd text-generation/

!cp /content/app.py .
!cp /content/requirements.txt .

!git add .
!git commit -m "Initial DeepSeek text generation app"

!git push

!huggingface-cli login

!git push
# -*- coding: utf-8 -*-
"""task3_4.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1N_1RA-fuxqiJinVcZIpPQJ8kEKs-EotM
"""

!pip install python-telegram-bot==20.7 groq nest_asyncio

import os

os.environ["TELEGRAM_BOT_TOKEN"] = "8588407313:AAEJRhEmjlfpsDv3fHfhLWQbbzsv0OjR-N0"
os.environ["GROQ_API_KEY"] = "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"

import os
import nest_asyncio
from groq import Groq
from telegram import Update
from telegram.ext import (
    ApplicationBuilder,
    ContextTypes,
    MessageHandler,
    filters,
)

nest_asyncio.apply()

TELEGRAM_BOT_TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GROQ_API_KEY = os.getenv("GROQ_API_KEY")

groq_client = Groq(api_key=GROQ_API_KEY)

def generate_ai_reply(user_message: str) -> str:
    completion = groq_client.chat.completions.create(
        model="llama-3.1-8b-instant",
        messages=[
            {"role": "system", "content": "You are a helpful AI assistant."},
            {"role": "user", "content": user_message}
        ],
        temperature=0.7,
        max_tokens=512
    )
    return completion.choices[0].message.content

async def handle_message(update: Update, context: ContextTypes.DEFAULT_TYPE):
    user_text = update.message.text
    ai_reply = generate_ai_reply(user_text)
    await update.message.reply_text(ai_reply)

app = ApplicationBuilder().token(TELEGRAM_BOT_TOKEN).build()
app.add_handler(MessageHandler(filters.TEXT & ~filters.COMMAND, handle_message))

print("Bot is running...")
await app.run_polling()